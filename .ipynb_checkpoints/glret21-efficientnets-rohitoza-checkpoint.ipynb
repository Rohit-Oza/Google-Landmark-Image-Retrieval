{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:51.234271Z",
     "iopub.status.busy": "2022-01-19T11:47:51.233960Z",
     "iopub.status.idle": "2022-01-19T11:47:51.237960Z",
     "shell.execute_reply": "2022-01-19T11:47:51.237087Z",
     "shell.execute_reply.started": "2022-01-19T11:47:51.234242Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install ../input/kerasapplications/ > /dev/null\n",
    "#!pip install ../input/efficientnet-keras-source-code/ > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:51.242261Z",
     "iopub.status.busy": "2022-01-19T11:47:51.242020Z",
     "iopub.status.idle": "2022-01-19T11:47:51.248574Z",
     "shell.execute_reply": "2022-01-19T11:47:51.247684Z",
     "shell.execute_reply.started": "2022-01-19T11:47:51.242239Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Optional, Tuple\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:51.250840Z",
     "iopub.status.busy": "2022-01-19T11:47:51.250208Z",
     "iopub.status.idle": "2022-01-19T11:47:51.259645Z",
     "shell.execute_reply": "2022-01-19T11:47:51.258835Z",
     "shell.execute_reply.started": "2022-01-19T11:47:51.250805Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    print(f\"[{name}]\")\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:51.262081Z",
     "iopub.status.busy": "2022-01-19T11:47:51.261412Z",
     "iopub.status.idle": "2022-01-19T11:47:51.268014Z",
     "shell.execute_reply": "2022-01-19T11:47:51.267196Z",
     "shell.execute_reply.started": "2022-01-19T11:47:51.262043Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extract(root_dir, n_models=4):\n",
    "    #return ids, embeddings\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:51.269776Z",
     "iopub.status.busy": "2022-01-19T11:47:51.269546Z",
     "iopub.status.idle": "2022-01-19T11:47:52.174364Z",
     "shell.execute_reply": "2022-01-19T11:47:52.173475Z",
     "shell.execute_reply.started": "2022-01-19T11:47:51.269755Z"
    }
   },
   "outputs": [],
   "source": [
    "DIRFILE = '../input/landmark-retrieval-2021/'\n",
    "\n",
    "index_data = f'{DIRFILE}/index'\n",
    "train_data_dir = f'{DIRFILE}/train'\n",
    "test_data_dir = f'{DIRFILE}/test'\n",
    "\n",
    "train = pd.read_csv(f'{DIRFILE}/train.csv')\n",
    "#sub = pd.read_csv(f'{DIRFILE}/train.csv')\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:47:52.177517Z",
     "iopub.status.busy": "2022-01-19T11:47:52.177157Z",
     "iopub.status.idle": "2022-01-19T11:47:52.189661Z",
     "shell.execute_reply": "2022-01-19T11:47:52.188691Z",
     "shell.execute_reply.started": "2022-01-19T11:47:52.177480Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions():\n",
    "    with timer(\"Getting Test Embeddings\"):\n",
    "        test_ids, test_embeddings = feature_extract(str(test_data_dir))\n",
    "        \n",
    "    with timer(\"Getting Train Embeddings\"):\n",
    "        train_ids, train_embeddings = feature_extract(str(train_data_dir))\n",
    "        \n",
    "    Prediction_List = []\n",
    "    \n",
    "    with timer('Matching...'):\n",
    "        for test_index in range(test_embeddings.shape[0]):\n",
    "            distances = spatial.distances.cdist(test_embeddings[np.newaxis, test_index, :],\n",
    "                                                train_embeddings, 'cosine')[0]\n",
    "            part = np.argpartition(distances, TOPK)[:TOPK]\n",
    "            nearest_matches = sorted([(train_ids[p], distances[p]) for p in part], key=lambda x:x[1])\n",
    "            pred_str = \"\"\n",
    "            for train_ids, cosine_dist in nearest_matches:\n",
    "                pred_str += train_id\n",
    "                pred_str += \" \"\n",
    "            Prediction_List.append(pred_str)\n",
    "            \n",
    "    return test_index, Prediction_List\n",
    "    \n",
    "        \n",
    "\n",
    "def main():\n",
    "    test_image_list = []\n",
    "    for root, dirs, files in os.walk(str(test_data_dir)):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                test_image_list.append(os.path.join(root,file))\n",
    "                \n",
    "    if len(test_image_list) == 1129:\n",
    "        sub_df = pd.read_csv('../input/land-mark-retrieval-2021/sample_submission.csv')\n",
    "        sub_df.to_csv('submission.csv', index=False)\n",
    "        return\n",
    "    \n",
    "    test_ids, PredictionStringList = get_predictions()\n",
    "    \n",
    "    sub_df = pd.DataFrame(data = {'id': test_ids, 'images':PredictionStringList})\n",
    "    sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "This notebook is based on [DELG_global_baseline](https://www.kaggle.com/wowfattie/delg-global-baseline)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
