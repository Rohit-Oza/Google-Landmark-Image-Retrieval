{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install ../input/kerasapplications/ > /dev/null\n#!pip install ../input/efficientnet-keras-source-code/ > /dev/null","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:51.233960Z","iopub.execute_input":"2022-01-19T11:47:51.234271Z","iopub.status.idle":"2022-01-19T11:47:51.237960Z","shell.execute_reply.started":"2022-01-19T11:47:51.234242Z","shell.execute_reply":"2022-01-19T11:47:51.237087Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **Libraries**","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport math\nimport random\nimport re\nimport warnings\nfrom pathlib import Path\nfrom PIL import Image\nfrom typing import Optional, Tuple\nfrom tensorflow.keras.applications import EfficientNetB0\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom scipy import spatial\nfrom sklearn.preprocessing import normalize\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:51.242020Z","iopub.execute_input":"2022-01-19T11:47:51.242261Z","iopub.status.idle":"2022-01-19T11:47:51.248574Z","shell.execute_reply.started":"2022-01-19T11:47:51.242239Z","shell.execute_reply":"2022-01-19T11:47:51.247684Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Settings","metadata":{}},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"import time\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    print(f\"[{name}]\")\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:51.250208Z","iopub.execute_input":"2022-01-19T11:47:51.250840Z","iopub.status.idle":"2022-01-19T11:47:51.259645Z","shell.execute_reply.started":"2022-01-19T11:47:51.250805Z","shell.execute_reply":"2022-01-19T11:47:51.258835Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"def feature_extract(root_dir, n_models=4):\n    #return ids, embeddings\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:51.261412Z","iopub.execute_input":"2022-01-19T11:47:51.262081Z","iopub.status.idle":"2022-01-19T11:47:51.268014Z","shell.execute_reply.started":"2022-01-19T11:47:51.262043Z","shell.execute_reply":"2022-01-19T11:47:51.267196Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"DIRFILE = '../input/landmark-retrieval-2021/'\n\nindex_data = f'{DIRFILE}/index'\ntrain_data_dir = f'{DIRFILE}/train'\ntest_data_dir = f'{DIRFILE}/test'\n\ntrain = pd.read_csv(f'{DIRFILE}/train.csv')\n#sub = pd.read_csv(f'{DIRFILE}/train.csv')\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:51.269546Z","iopub.execute_input":"2022-01-19T11:47:51.269776Z","iopub.status.idle":"2022-01-19T11:47:52.174364Z","shell.execute_reply.started":"2022-01-19T11:47:51.269755Z","shell.execute_reply":"2022-01-19T11:47:52.173475Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_predictions():\n    with timer(\"Getting Test Embeddings\"):\n        test_ids, test_embeddings = feature_extract(str(test_data_dir))\n        \n    with timer(\"Getting Train Embeddings\"):\n        train_ids, train_embeddings = feature_extract(str(train_data_dir))\n        \n    Prediction_List = []\n    \n    with timer('Matching...'):\n        for test_index in range(test_embeddings.shape[0]):\n            distances = spatial.distances.cdist(test_embeddings[np.newaxis, test_index, :],\n                                                train_embeddings, 'cosine')[0]\n            part = np.argpartition(distances, TOPK)[:TOPK]\n            nearest_matches = sorted([(train_ids[p], distances[p]) for p in part], key=lambda x:x[1])\n            pred_str = \"\"\n            for train_ids, cosine_dist in nearest_matches:\n                pred_str += train_id\n                pred_str += \" \"\n            Prediction_List.append(pred_str)\n            \n    return test_index, Prediction_List\n    \n        \n\ndef main():\n    test_image_list = []\n    for root, dirs, files in os.walk(str(test_data_dir)):\n        for file in files:\n            if file.endswith('.jpg'):\n                test_image_list.append(os.path.join(root,file))\n                \n    if len(test_image_list) == 1129:\n        sub_df = pd.read_csv('../input/land-mark-retrieval-2021/sample_submission.csv')\n        sub_df.to_csv('submission.csv', index=False)\n        return\n    \n    test_ids, PredictionStringList = get_predictions()\n    \n    sub_df = pd.DataFrame(data = {'id': test_ids, 'images':PredictionStringList})\n    sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T11:47:52.177157Z","iopub.execute_input":"2022-01-19T11:47:52.177517Z","iopub.status.idle":"2022-01-19T11:47:52.189661Z","shell.execute_reply.started":"2022-01-19T11:47:52.177480Z","shell.execute_reply":"2022-01-19T11:47:52.188691Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"This notebook is based on [DELG_global_baseline](https://www.kaggle.com/wowfattie/delg-global-baseline).","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}}]}